## ðŸ“ Sentiment Analysis from Social Media Dataset

This project performs **multi-class sentiment classification** on social media text using TF-IDF vectorization, **SMOTE** for handling imbalanced classes, and various supervised machine learning models with **hyperparameter tuning** via `RandomizedSearchCV`.

---

### ðŸ“ Dataset

| Column   | Description                                    |
|----------|------------------------------------------------|
| `Text`   | Raw user text                                  |
| `Sentiment` | Labeled emotion/sentiment (e.g., Happy, Angry, Love) |

**Input File:** `sentimentdataset (1).csv`

---

### ðŸ” Sentiment Simplification

| Original Labels                    | Mapped To   |
|------------------------------------|-------------|
| Joy, Love, Excited, etc.           | **Positive** |
| Sad, Angry, Fear, etc.             | **Negative** |
| Surprise, Confusion, etc.          | **Neutral**  |

---

### ðŸ§ª Workflow

âœ… **1. Preprocessing**  
â€¢ Stripped whitespace from sentiment labels  
â€¢ Mapped detailed emotions into 3 main classes (Positive, Negative, Neutral)

âœ… **2. Feature Engineering**  
â€¢ Applied `TfidfVectorizer` with n-grams (trigram), `max_features=6000`, `min_df=3`, `max_df=0.6`  
â€¢ Converted text into numerical feature vectors

âœ… **3. Label Encoding**  
â€¢ Encoded target labels into integers using `LabelEncoder`

âœ… **4. Handle Imbalance**  
â€¢ Used `SMOTE` to oversample minority classes and balance the dataset

âœ… **5. Train-Test Split**  
â€¢ Splitted data into 80% train / 20% test with **stratification**

âœ… **6. Hyperparameter Tuning**  
Applied `RandomizedSearchCV` for the following classifiers:

| Model               | Parameters Tuned (Examples)      |
|---------------------|----------------------------------|
| Random Forest        | `n_estimators`, `max_depth`      |
| Logistic Regression  | `C`, `penalty`                   |
| SVM                  | `C`, `gamma`, `kernel`           |
| Decision Tree        | `max_depth`, `min_samples_split` |

> _(Optional)_ Other models like **Naive Bayes**, **XGBoost**, **KNN** can also be added

---

### ðŸ“Š Evaluation Metrics

- Classification report  
- **F1-score**  
- **Recall / Precision**  
- Confusion Matrix  
- ROC Curve & AUC (where applicable)

---

### ðŸŽ¯ Goal

To **identify the best-performing model** for sentiment classification across three categories (**Positive**, **Negative**, **Neutral**), ensuring robust performance even on **imbalanced data**.

---

### ðŸ“š Libraries Used

pandas, numpy, matplotlib, seaborn
sklearn: preprocessing, models, metrics, cross-validation
xgboost, imblearn, scipy.stats
